# ui/app.py â€” robust local desktop version
import sys
from pathlib import Path

import torch
import gradio as gr
from PIL import Image
from torchvision import transforms

# --- å°ˆæ¡ˆæ ¹ç›®éŒ„ & è·¯å¾‘ ---
ROOT = Path(__file__).resolve().parents[1]
SRC = ROOT / "src"
if str(SRC) not in sys.path:
    sys.path.insert(0, str(SRC))

from cyclegan_min import GeneratorResnet  # âœ… ä½ åŸæœ¬çš„æ¨¡å‹

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
USE_AMP = DEVICE.type == "cuda"

DEFAULT_CKPT = ROOT / "result1" / "checkpoints" / "cyclegan_ultra_epoch_01.pt"

# ---------------------------
# 1. è¼‰å…¥æ¨¡å‹ï¼ˆé€™æ®µè«‹ä½ ä¾ç…§ä½ åŸæœ¬çš„ç‰ˆæœ¬å¾®èª¿ï¼‰
# ---------------------------

_G_AB = None          # global generator
_TRANSFORM = None     # global preprocess
_DENORM_MEAN = [0.5, 0.5, 0.5]
_DENORM_STD = [0.5, 0.5, 0.5]


def _build_transform(img_size: int) -> transforms.Compose:
    return transforms.Compose([
        transforms.Resize((img_size, img_size), interpolation=transforms.InterpolationMode.BICUBIC),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),
    ])


def _load_model():
    global _G_AB, _TRANSFORM

    state = torch.load(DEFAULT_CKPT, map_location=DEVICE)

    # å¾ checkpoint æ‹¿ meta
    img_size = int(state.get("img_size", 64))
    n_res = int(state.get("n_res", 2))

    # å»ºç«‹æ¨¡å‹ï¼ˆé€™è£¡ä¾ä½  cyclegan_min.GeneratorResnet çš„åƒæ•¸èª¿ï¼‰
    # å¦‚æœä½ çš„ __init__ é•·å¾—ä¸ä¸€æ¨£ï¼Œè«‹åªæ”¹é€™ä¸€è¡Œ
    _G_AB = GeneratorResnet(n_res=n_res).to(DEVICE)

    # checkpoint å…§å®¹å¯èƒ½æ˜¯ï¼š
    # 1) {"G_AB": state_dict, "G_BA": ... , "img_size": ..., "n_res": ...}
    # 2) æˆ–ç›´æ¥æ˜¯ state_dict
    if "G_AB" in state:
        G_AB_state = state["G_AB"]
    else:
        G_AB_state = state

    _G_AB.load_state_dict(G_AB_state)
    _G_AB.eval()

    _TRANSFORM = _build_transform(img_size)

    print(f"[INFO] Model loaded. img_size={img_size}, n_res={n_res}, device={DEVICE}")


# å•Ÿå‹•æ™‚å°±å…ˆè¼‰å…¥ä¸€æ¬¡
_load_model()


# ---------------------------
# 2. æ¨è«–å‡½æ•¸ï¼ˆCPU ç‰ˆå„ªåŒ–ï¼‰
# ---------------------------

def translate_image(pil_img: Image.Image) -> Image.Image:
    """æŠŠä¸Šå‚³çš„åœ–ç‰‡ â†’ è½‰æˆé›»å½±é¢¨æ ¼åœ–ç‰‡"""
    if pil_img is None:
        return None

    # å‰è™•ç†
    x = _TRANSFORM(pil_img).unsqueeze(0).to(DEVICE)

    with torch.no_grad():  # âœ… æ¨è«–ä¸éœ€è¦æ¢¯åº¦ï¼Œçœå¾ˆå¤šæ™‚é–“
        if USE_AMP:
            with torch.cuda.amp.autocast(dtype=torch.float16):
                y = _G_AB(x)
        else:
            y = _G_AB(x)

    # å¾Œè™•ç†ï¼šå¾ [-1, 1] é‚„åŸå› [0, 255]
    y = y[0].detach().cpu()
    for c in range(3):
        y[c] = y[c] * _DENORM_STD[c] + _DENORM_MEAN[c]
    y = torch.clamp(y, 0.0, 1.0)

    y_np = (y.permute(1, 2, 0).numpy() * 255).astype("uint8")
    return Image.fromarray(y_np)


# ---------------------------
# 3. Gradio UIï¼ˆDeliverable 3 å®Œæ•´ç‰ˆï¼‰
# ---------------------------

def build_demo():
    with gr.Blocks(title="Ancient Painting â†’ Film Style (CycleGAN)") as demo:
        gr.Markdown("# Ancient Painting â†’ Film Style Translation")
        gr.Markdown(
            "ä¸Šå‚³ä¸€å¼µå¤ç•«é¢¨æ ¼åœ–ç‰‡ï¼Œæ¨¡å‹æœƒæŠŠå®ƒè½‰æ›æˆé›»å½±é¢¨æ ¼å½±åƒã€‚\n"
            "é€™å€‹ä»‹é¢æ˜¯ Deliverable 3 çš„æœ€çµ‚é››å‹ã€‚"
        )

        gr.Markdown(f"**Device:** `{DEVICE}` &nbsp;&nbsp; **Using AMP:** `{USE_AMP}`")
        gr.Markdown(f"**Checkpoint:** `{DEFAULT_CKPT}`")

        with gr.Row():
            with gr.Column():
                input_img = gr.Image(
                    label="è¼¸å…¥åœ–ç‰‡ï¼ˆå¤ç•«ï¼‰",
                    type="pil"
                )

                gr.Markdown("å¦‚æœæ²’æœ‰åœ–ç‰‡ï¼Œå¯ä»¥å…ˆç”¨ä¸€å¼µç¯„ä¾‹åœ–ï¼š")

                # âš ï¸ é€™é‚Šè«‹ä½ æŠŠè·¯å¾‘æ”¹æˆä½ å¯¦éš›æœ‰çš„ä¸€å¼µåœ–ç‰‡ï¼Œä¾‹å¦‚ A è£¡é¢çš„ä¸€å¼µ
                SAMPLE_PATH = ROOT / "A" / "sample_01.jpg"

                def load_sample():
                    if SAMPLE_PATH.exists():
                        return Image.open(SAMPLE_PATH)
                    else:
                        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œç¶­æŒç©ºç™½
                        return None

                sample_btn = gr.Button("è¼‰å…¥ç¯„ä¾‹åœ–ç‰‡")
                sample_btn.click(fn=load_sample, outputs=input_img)

                clear_btn = gr.Button("æ¸…ç©ºè¼¸å…¥")
                clear_btn.click(fn=lambda: None, outputs=input_img)

            with gr.Column():
                output_img = gr.Image(
                    label="è¼¸å‡ºåœ–ç‰‡ï¼ˆé›»å½±é¢¨æ ¼ï¼‰",
                    type="pil"
                )
                status = gr.Markdown("ç‹€æ…‹ï¼šğŸŸ¢ å°±ç·’")

                def wrapped_translate(img):
                    if img is None:
                        return None, "ç‹€æ…‹ï¼šâš ï¸ è«‹å…ˆä¸Šå‚³æˆ–è¼‰å…¥ä¸€å¼µåœ–ç‰‡"
                    out = translate_image(img)
                    return out, "ç‹€æ…‹ï¼šâœ… å®Œæˆæ¨è«–"

                run_btn = gr.Button("é–‹å§‹è½‰æ›", variant="primary")
                run_btn.click(
                    fn=wrapped_translate,
                    inputs=input_img,
                    outputs=[output_img, status]
                )

        return demo


if __name__ == "__main__":
    demo = build_demo()
    demo.queue()   # ä¿ç•™ queueï¼Œä¹‹å¾Œä½ å¯ä»¥åœ¨å ±å‘Šèªªæœ‰æ’éšŠæ©Ÿåˆ¶
    demo.launch()


